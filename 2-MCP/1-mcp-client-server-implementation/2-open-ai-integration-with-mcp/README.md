# ğŸ¤– OpenAI Integration with MCP

This example demonstrates how to integrate the **Model Context Protocol (MCP)** with OpenAI's API to build a system where OpenAI can access and use tools provided by your MCP server.

---

## ğŸ“Œ Overview

This project shows how to:

- âœ… Create an MCP server that exposes a knowledge base tool
- âœ… Connect OpenAI to the MCP server using the MCP client
- âœ… Allow OpenAI to dynamically select and use tools when generating responses

---

## ğŸ”Œ Connection Method

This example uses **`stdio` transport** for communication between the OpenAI client and the MCP server.

- âš™ï¸ Client and server run in the **same process**
- âš¡ Client **launches the server** as a subprocess
- ğŸ§© No separate long-running server is needed

---

## ğŸ§  How OpenAI Executes Tools via MCP

OpenAI's function calling works seamlessly with MCP tools through the following flow:

1. **Tool Registration**  
   MCP client exposes its tools in OpenAIâ€™s function call format.

2. **Tool Choice**  
   OpenAI automatically chooses the most relevant tool based on the user query.

3. **Tool Execution**  
   The MCP client invokes the selected tool and returns the result.

4. **Context Integration**  
   OpenAI integrates the tool result directly into its final response.

---

## ğŸ› ï¸ Implementation Details

### `server.py` â€” MCP Server

- Exposes a tool: `get_knowledge_base`
- Retrieves Q&A pairs from a JSON knowledge base
- Serves tool responses on request from OpenAI

---

### `client.py` â€” MCP Client

- Launches and connects to the MCP server
- Translates MCP tools into OpenAI-compatible function schema
- Routes queries and tool results between OpenAI and the MCP server
- Returns enriched OpenAI responses using tool outputs

---

### `data/kb.json` â€” Knowledge Base

- A JSON file containing structured Q&A data
- Used by the `get_knowledge_base` tool
- Can be extended to include any domain-specific policy or FAQ information

---

## âœ… Example Use Case

Ask OpenAI something like:
"What is the company's remote work policy?"


OpenAI will:

1. Select the `get_knowledge_base` tool
2. Query the MCP server
3. Use the result to generate a detailed and accurate answer

---

## ğŸ“ Notes

- This integration serves as a reference architecture for building **RAG-style LLM systems** using MCP and OpenAI.
- You can extend this project by adding more tools, datasets, or even switching transport methods (`stdio` â†’ `http`, `websocket`, etc.).


